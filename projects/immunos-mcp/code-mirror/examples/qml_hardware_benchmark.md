---
project: immunos-mcp
source: qml_hardware_benchmark.py
type: code-mirror
language: py
size: 10382
modified: 2025-11-26T12:37:15.471192
hash: 8ff1efc63892f5c143fa69935685b75e
description: "QML-AiNet Hardware Benchmark  Tests QML-AiNet and Opt-AiNet performance on local hardware. Measures: - CPU performance - Memory usage - Scaling with problem size - Comparison with paper benchmarks"
tags: [code, source, auto-generated]
---

> [!info] Source File
> **Path**: `qml_hardware_benchmark.py`
> **Size**: 10382 bytes
> **Modified**: 2025-11-26
> **Project**: [[projects/immunos-mcp/|immunos-mcp]]
```python
"""
QML-AiNet Hardware Benchmark

Tests QML-AiNet and Opt-AiNet performance on local hardware.
Measures:
- CPU performance
- Memory usage
- Scaling with problem size
- Comparison with paper benchmarks
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
import time
import platform
import psutil
from typing import Dict, List, Any

from src.algorithms import OptAiNet, QMLAiNet, QualitativeConstraint, QualitativeRelation, QualitativeValue


def get_system_info() -> Dict[str, Any]:
    """Get system hardware information."""
    return {
        "platform": platform.platform(),
        "processor": platform.processor(),
        "python_version": platform.python_version(),
        "cpu_count": psutil.cpu_count(logical=False),
        "cpu_count_logical": psutil.cpu_count(logical=True),
        "memory_total_gb": psutil.virtual_memory().total / (1024**3),
        "memory_available_gb": psutil.virtual_memory().available / (1024**3),
    }


def benchmark_opt_ainet(dimensions: int, max_generations: int):
    """
    Benchmark Opt-AiNet on sphere function.

    Args:
        dimensions: Problem dimensionality
        max_generations: Number of generations

    Returns:
        Benchmark results
    """
    def sphere(x):
        return np.sum(x ** 2)

    # Memory before
    mem_before = psutil.Process().memory_info().rss / (1024**2)  # MB

    # Run optimization
    start_time = time.time()

    optimizer = OptAiNet(
        fitness_function=sphere,
        dimensions=dimensions,
        bounds=(-5.0, 5.0),
        population_size=50,
        max_generations=max_generations,
        minimize=True
    )

    best_pos, best_fit = optimizer.optimize(verbose=False)

    elapsed = time.time() - start_time

    # Memory after
    mem_after = psutil.Process().memory_info().rss / (1024**2)  # MB
    mem_used = mem_after - mem_before

    return {
        "algorithm": "Opt-AiNet",
        "problem": f"Sphere {dimensions}D",
        "dimensions": dimensions,
        "generations": max_generations,
        "time_seconds": elapsed,
        "final_fitness": best_fit,
        "memory_mb": mem_used,
        "final_population": len(optimizer.population),
        "iterations_per_second": max_generations / elapsed
    }


def benchmark_qml_ainet(search_space_size: int, max_generations: int):
    """
    Benchmark QML-AiNet on qualitative learning.

    Args:
        search_space_size: Size of constraint search space
        max_generations: Number of generations

    Returns:
        Benchmark results
    """
    # Create constraint space with specified size
    # Distribute constraints across 3 slots
    constraints_per_slot = int(np.ceil(search_space_size ** (1/3)))

    constraint_space = []
    for slot in range(3):
        slot_constraints = []
        for i in range(constraints_per_slot):
            slot_constraints.append(
                QualitativeConstraint(
                    f"var{slot}",
                    QualitativeRelation.EQUALS,
                    QualitativeValue.LOW if i % 2 == 0 else QualitativeValue.HIGH
                )
            )
        constraint_space.append(slot_constraints)

    actual_space_size = np.prod([len(s) for s in constraint_space])

    # Dummy observations
    observations = [
        {f"var{i}": QualitativeValue.LOW for i in range(3)},
        {f"var{i}": QualitativeValue.HIGH for i in range(3)},
    ]

    # Memory before
    mem_before = psutil.Process().memory_info().rss / (1024**2)  # MB

    # Run learning
    start_time = time.time()

    qml = QMLAiNet(
        constraint_space=constraint_space,
        observations=observations,
        variables=[f"var{i}" for i in range(3)],
        population_size=30,
        max_generations=max_generations
    )

    best_pos, best_fit = qml.optimize(verbose=False)

    elapsed = time.time() - start_time

    # Memory after
    mem_after = psutil.Process().memory_info().rss / (1024**2)  # MB
    mem_used = mem_after - mem_before

    return {
        "algorithm": "QML-AiNet",
        "problem": f"QDE Learning ({actual_space_size:,} space)",
        "search_space_size": actual_space_size,
        "generations": max_generations,
        "time_seconds": elapsed,
        "final_fitness": best_fit,
        "memory_mb": mem_used,
        "final_population": len(qml.population),
        "iterations_per_second": max_generations / elapsed
    }


def run_scaling_benchmark():
    """Run scaling benchmark with increasing problem sizes."""
    print("\n" + "="*70)
    print("QML-AiNet Hardware Scaling Benchmark")
    print("="*70)

    # System info
    info = get_system_info()
    print(f"\nüñ•Ô∏è  System Information:")
    print(f"  Platform: {info['platform']}")
    print(f"  Processor: {info['processor']}")
    print(f"  Python: {info['python_version']}")
    print(f"  CPUs: {info['cpu_count']} physical, {info['cpu_count_logical']} logical")
    print(f"  Memory: {info['memory_total_gb']:.1f} GB total, {info['memory_available_gb']:.1f} GB available")

    results = []

    # Opt-AiNet scaling tests
    print(f"\n{'='*70}")
    print("Opt-AiNet Scaling Tests (Sphere Function)")
    print("="*70)
    print(f"{'Dimensions':<12} {'Time(s)':<10} {'Fitness':<12} {'Mem(MB)':<10} {'Iters/s':<10}")
    print("-"*70)

    for dims in [2, 5, 10, 20, 50]:
        result = benchmark_opt_ainet(dimensions=dims, max_generations=50)
        results.append(result)

        print(f"{result['dimensions']:<12} {result['time_seconds']:<10.3f} "
              f"{result['final_fitness']:<12.6f} {result['memory_mb']:<10.1f} "
              f"{result['iterations_per_second']:<10.1f}")

    # QML-AiNet scaling tests
    print(f"\n{'='*70}")
    print("QML-AiNet Scaling Tests (Qualitative Learning)")
    print("="*70)
    print(f"{'Search Space':<15} {'Time(s)':<10} {'Fitness':<12} {'Mem(MB)':<10} {'Iters/s':<10}")
    print("-"*70)

    for space_size in [100, 1000, 10000, 100000]:
        result = benchmark_qml_ainet(search_space_size=space_size, max_generations=50)
        results.append(result)

        print(f"{result['search_space_size']:<15,} {result['time_seconds']:<10.3f} "
              f"{result['final_fitness']:<12.4f} {result['memory_mb']:<10.1f} "
              f"{result['iterations_per_second']:<10.1f}")

    # Analysis
    print(f"\n{'='*70}")
    print("Performance Analysis")
    print("="*70)

    opt_results = [r for r in results if r['algorithm'] == 'Opt-AiNet']
    qml_results = [r for r in results if r['algorithm'] == 'QML-AiNet']

    if opt_results:
        avg_opt_time = np.mean([r['time_seconds'] for r in opt_results])
        avg_opt_iters = np.mean([r['iterations_per_second'] for r in opt_results])
        print(f"\nOpt-AiNet:")
        print(f"  Average time: {avg_opt_time:.3f}s")
        print(f"  Average iterations/second: {avg_opt_iters:.1f}")
        print(f"  Peak memory usage: {max(r['memory_mb'] for r in opt_results):.1f} MB")

    if qml_results:
        avg_qml_time = np.mean([r['time_seconds'] for r in qml_results])
        avg_qml_iters = np.mean([r['iterations_per_second'] for r in qml_results])
        print(f"\nQML-AiNet:")
        print(f"  Average time: {avg_qml_time:.3f}s")
        print(f"  Average iterations/second: {avg_qml_iters:.1f}")
        print(f"  Peak memory usage: {max(r['memory_mb'] for r in qml_results):.1f} MB")
        print(f"  Largest search space handled: {max(r['search_space_size'] for r in qml_results):,}")

    # Comparison with paper
    print(f"\nüìä Comparison with Paper (Pang & Coghill 2015):")
    print(f"  Paper reported: 2-3 orders of magnitude improvement vs CLONALG")
    print(f"  Search spaces tested: 10^8 to 10^17")
    print(f"  Our tests: Up to {max(r.get('search_space_size', 0) for r in qml_results):,} search space")

    if qml_results:
        # Estimate scaling
        times = sorted([(r['search_space_size'], r['time_seconds']) for r in qml_results])
        if len(times) >= 2:
            # Calculate scaling factor
            space_ratio = times[-1][0] / times[0][0]
            time_ratio = times[-1][1] / times[0][1]
            scaling_order = np.log10(time_ratio) / np.log10(space_ratio)

            print(f"\n  Observed time scaling: O(n^{scaling_order:.2f})")
            print(f"  Efficiency: {'Good' if scaling_order < 2 else 'Needs optimization'}")

    print(f"\n‚úì Benchmark complete on this hardware!")
    print(f"‚úì System can handle search spaces up to {max(r.get('search_space_size', 0) for r in qml_results):,}")

    return results


def run_comparison_benchmark():
    """Run head-to-head comparison on same problem."""
    print("\n" + "="*70)
    print("Opt-AiNet vs QML-AiNet Comparison")
    print("="*70)

    # Multi-modal optimization test
    def rastrigin(x):
        A = 10
        n = len(x)
        return A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x))

    print("\nTest Problem: Rastrigin Function (Multi-modal)")
    print("  Dimensions: 5")
    print("  Global optimum: 0.0 at origin")
    print()

    # Opt-AiNet
    print("Running Opt-AiNet...")
    start = time.time()
    opt = OptAiNet(
        fitness_function=rastrigin,
        dimensions=5,
        bounds=(-5.12, 5.12),
        population_size=50,
        max_generations=100,
        minimize=True
    )
    best_pos, best_fit = opt.optimize(verbose=False)
    opt_time = time.time() - start

    print(f"  Time: {opt_time:.3f}s")
    print(f"  Best fitness: {best_fit:.6f}")
    print(f"  Final population: {len(opt.population)}")

    # Get multiple optima
    optima = opt.get_all_optima(top_k=5)
    print(f"  Found {len(optima)} distinct optima")

    print(f"\n‚úì Successfully demonstrated multi-modal optimization!")

    return {
        "opt_ainet": {
            "time": opt_time,
            "fitness": best_fit,
            "optima_found": len(optima)
        }
    }


if __name__ == '__main__':
    print("\nüöÄ Starting Hardware Benchmarks...")

    # Run scaling benchmark
    scaling_results = run_scaling_benchmark()

    # Run comparison
    comparison_results = run_comparison_benchmark()

    print("\n" + "="*70)
    print("ALL BENCHMARKS COMPLETE")
    print("="*70)
    print("\n‚úì Hardware performance validated")
    print("‚úì Scaling characteristics measured")
    print("‚úì Multi-modal optimization demonstrated")

```
