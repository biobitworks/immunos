{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header-title"
   },
   "source": [
    "# Late-Stage Mitochondrial Dysregulation and Mitophagy Failure: Evaluation Notebook\n",
    "\n",
    "This is a working notebook for performing Kosmos data analysis evaluation. You'll find instructions for how to use this notebook below.\n",
    "\n",
    "If you are not familiar with Colab Notebooks, please visit the welcome notebook at: https://colab.research.google.com/notebooks/intro.ipynb. In short, they function similarly to standard Jupyter Notebooks, but are more shareable for our purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instructions"
   },
   "source": [
    "## Instructions - IMPORTANT, READ CAREFULLY\n",
    "\n",
    "This notebook has been created for your specific use, and you should work directly in it. DO NOT download the notebook and work locally and reupload.\n",
    "\n",
    "All cells of the notebook should be run in the place and left as-is so outputs can be inspected.\n",
    "\n",
    "All code should be written in Python as well as use terminal commands. If you need to conduct single-cell analysis, use the scanpy package.\n",
    "\n",
    "Please be highly verbose using markdown cells to outline the high-level steps taken including rationale behind decisions made for using various tools or carrying out specific steps. You should use inline comments diligently to explain each code block's purpose.\n",
    "\n",
    "It is also helpful if you are liberal in your use of separate code cells rather than including too much code together in a single cell.\n",
    "\n",
    "You may import external packages at the top or load them throughout the code. Feel free to do so in whichever way is most natural to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "file-handling"
   },
   "source": [
    "## File handling\n",
    "\n",
    "You'll find any necessary input files in the same folder you found this notebook in. They should be uploaded to the notebook environment by clicking on the folder icon on the left. These are stored in a /content/ directory. They can be programmatically accessed simply with the filename.\n",
    "\n",
    "Output files you write are also written to the /content/ directory. You can view this directory at any time by clicking the folder icon.\n",
    "\n",
    "As always, if you have any questions do not hesitate to reach out to Jon via Slack or email (jon@futurehouse.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis-overview"
   },
   "source": [
    "---\n",
    "\n",
    "# Research Analysis Overview\n",
    "\n",
    "## Biological Context: Mitochondrial Dysfunction and Mitophagy Failure in Neurodegeneration\n",
    "\n",
    "Mitochondrial dysfunction is a hallmark of neurodegenerative diseases, particularly in late-stage disease progression. The failure of mitophagy (selective autophagy of mitochondria) leads to the accumulation of damaged mitochondria, contributing to neuronal death.\n",
    "\n",
    "### Key Molecular Players:\n",
    "1. **SQSTM1/p62**: Autophagy receptor that can target mitochondria for mitophagy\n",
    "2. **VDAC1**: Voltage-dependent anion channel, mitochondrial outer membrane protein\n",
    "3. **CYCS**: Cytochrome c, critical for both respiration and apoptosis\n",
    "4. **UPS Proteins**: Ubiquitin-proteasome system components\n",
    "5. **Autophagy Machinery**: BECN1, CTSD, ATG12, ULK1, CTSL\n",
    "\n",
    "### Research Hypothesis:\n",
    "In late-stage neurodegeneration, mitophagy becomes increasingly dysregulated, leading to a shift from protective to pathological processes. This manifests as altered protein expression patterns and correlation changes along disease progression (pseudotime).\n",
    "\n",
    "### Analytical Framework:\n",
    "This notebook will rigorously evaluate 8 specific biological claims about mitochondrial dysregulation and mitophagy failure using:\n",
    "- Differential expression analysis\n",
    "- Correlation analysis (global and temporal)\n",
    "- Sliding window analysis along pseudotime\n",
    "- Biphasic pattern detection\n",
    "- Statistical validation with appropriate multiple testing correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-loading-header"
   },
   "source": [
    "# Data loading\n",
    "\n",
    "Load any local or remote data in this section.\n",
    "\n",
    "For each data file or set of related files, include a brief description as a comment above or at the end of the loading call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-scanpy"
   },
   "outputs": [],
   "source": [
    "# Install scanpy via pip. Remove hashtag if needed.\n",
    "# Scanpy is essential for reading and manipulating h5ad format proteomics data\n",
    "# It provides the infrastructure for single-cell/proteomics analysis\n",
    "!pip install scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-scanpy"
   },
   "outputs": [],
   "source": [
    "# We need to load the package to read and load the data file.\n",
    "# For python, scanpy is a package needed to conduct single cell analysis.\n",
    "# So, we import the scanpy package as sc for convenience.\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-core-libraries"
   },
   "outputs": [],
   "source": [
    "# Import essential data manipulation and analysis libraries\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import numpy as np   # Numerical computing and array operations\n",
    "import scipy.stats as stats  # Statistical functions and tests\n",
    "from scipy.signal import find_peaks  # For peak detection in sliding window analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-advanced-stats"
   },
   "outputs": [],
   "source": [
    "# Import advanced statistical libraries for comprehensive analysis\n",
    "import statsmodels.api as sm  # Statistical modeling\n",
    "from statsmodels.stats.multitest import multipletests  # Multiple testing correction\n",
    "from sklearn.linear_model import LinearRegression  # For regression analysis\n",
    "from sklearn.preprocessing import StandardScaler  # Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-visualization"
   },
   "outputs": [],
   "source": [
    "# Import visualization libraries for publication-quality plots\n",
    "import matplotlib.pyplot as plt  # Basic plotting functionality\n",
    "import seaborn as sns           # Statistical data visualization\n",
    "from matplotlib.patches import Rectangle  # For custom plot elements\n",
    "import matplotlib.patches as mpatches     # For legend customization\n",
    "\n",
    "# Configure plotting parameters for publication quality\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "sns.set_style(\"whitegrid\")  # Clean, professional appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-main-data"
   },
   "outputs": [],
   "source": [
    "# We can use the scanpy.read_h5ad() function to load the data.\n",
    "# We need to alter the function to sc.read_h5ad() due to the import.\n",
    "# The data file was uploaded to the /content/ directory per instructions.\n",
    "adata = sc.read_h5ad('/content/pool_processed_v2.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inspect-data"
   },
   "outputs": [],
   "source": [
    "# We want to inspect the data to verify.\n",
    "# Printing the data provides the contents with dimensions.\n",
    "print(adata)\n",
    "print(f\"\\nDataset successfully loaded:\")\n",
    "print(f\"- Samples (neuronal pools): {adata.n_obs}\")\n",
    "print(f\"- Proteins quantified: {adata.n_vars}\")\n",
    "print(f\"- Data matrix type: {type(adata.X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-exploration-header"
   },
   "source": [
    "# Data exploration\n",
    "\n",
    "Include data exploration here, including reading the structure of the data files such as column names, sample ID formats, etc.\n",
    "\n",
    "## Understanding Dataset Structure for Mitochondrial Analysis\n",
    "\n",
    "Before analyzing mitochondrial dysfunction and mitophagy failure, we need to understand:\n",
    "- Sample metadata structure and key variables\n",
    "- Protein annotation format\n",
    "- Expression data characteristics\n",
    "- Presence of target proteins for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore-data-structure"
   },
   "outputs": [],
   "source": [
    "# AnnData is a core package within scanpy.\n",
    "# AnnData is a Python package that handles annotated data matrices.\n",
    "\n",
    "# We can access the shape of the data, which provides the dimensions.\n",
    "# (n_observations, n_variables)\n",
    "print(f\"Data shape: {adata.shape}\")\n",
    "print(f\"Observations (samples): {adata.n_obs}\")\n",
    "print(f\"Variables (proteins): {adata.n_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore-sample-metadata"
   },
   "outputs": [],
   "source": [
    "# We can verify that the observations contain information about each sample.\n",
    "print(\"=== SAMPLE METADATA OVERVIEW ===\")\n",
    "print(\"Available columns in .obs:\")\n",
    "for col in adata.obs.columns:\n",
    "    dtype = adata.obs[col].dtype\n",
    "    unique_vals = adata.obs[col].nunique()\n",
    "    print(f\"  - {col}: {dtype} ({unique_vals} unique values)\")\n",
    "\n",
    "print(\"\\n=== SAMPLE METADATA PREVIEW ===\")\n",
    "print(adata.obs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore-key-variables"
   },
   "outputs": [],
   "source": [
    "# Examine key variables critical for mitochondrial analysis\n",
    "print(\"=== KEY VARIABLES FOR MITOCHONDRIAL ANALYSIS ===\")\n",
    "\n",
    "# Tau status distribution - critical for differential expression\n",
    "print(\"Tau Status Distribution:\")\n",
    "tau_counts = adata.obs['TauStatus'].value_counts()\n",
    "print(tau_counts)\n",
    "print(f\"Tau-positive: {tau_counts.get('positive', 0)} samples\")\n",
    "print(f\"Tau-negative: {tau_counts.get('negative', 0)} samples\")\n",
    "\n",
    "# Pseudotime distribution - critical for temporal analysis\n",
    "print(\"\\nPseudotime Statistics:\")\n",
    "print(adata.obs['pseudotime'].describe())\n",
    "\n",
    "# MC1 scores - important for biphasic analysis\n",
    "print(\"\\nMC1 Score Statistics:\")\n",
    "print(adata.obs['MC1'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore-protein-annotations"
   },
   "outputs": [],
   "source": [
    "# We can confirm that the variables contain information about each protein.\n",
    "print(\"=== PROTEIN ANNOTATION OVERVIEW ===\")\n",
    "print(\"Available columns in .var:\")\n",
    "for col in adata.var.columns:\n",
    "    dtype = adata.var[col].dtype\n",
    "    non_null = adata.var[col].notna().sum()\n",
    "    print(f\"  - {col}: {dtype} ({non_null}/{len(adata.var)} non-null)\")\n",
    "\n",
    "print(\"\\n=== PROTEIN ANNOTATION PREVIEW ===\")\n",
    "print(adata.var.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore-expression-data"
   },
   "outputs": [],
   "source": [
    "# We can view the values of the matrix.\n",
    "# We can view the expression using the pandas DataFrame.\n",
    "# We can see the values are the Log2-transformed protein expression levels.\n",
    "print(\"=== EXPRESSION DATA CHARACTERISTICS ===\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "expr_df = adata.to_df()\n",
    "\n",
    "print(f\"Expression data shape: {expr_df.shape}\")\n",
    "print(f\"Data type: {expr_df.dtypes.iloc[0]}\")\n",
    "print(f\"\\nExpression statistics:\")\n",
    "print(f\"  Range: {expr_df.values.min():.3f} to {expr_df.values.max():.3f}\")\n",
    "print(f\"  Mean: {expr_df.values.mean():.3f}\")\n",
    "print(f\"  Std: {expr_df.values.std():.3f}\")\n",
    "print(f\"  Missing values: {expr_df.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\n=== SAMPLE EXPRESSION VALUES ===\")\n",
    "print(\"First 5 samples x 5 proteins:\")\n",
    "print(expr_df.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "identify-target-proteins"
   },
   "outputs": [],
   "source": [
    "# Identify key proteins for mitochondrial dysfunction analysis\n",
    "print(\"=== IDENTIFYING TARGET PROTEINS ===\")\n",
    "\n",
    "# Define target proteins for our analysis based on the claims\n",
    "target_proteins = {\n",
    "    'SQSTM1': ['SQSTM1', 'sequestosome', 'p62'],  # Autophagy receptor\n",
    "    'VDAC1': ['VDAC1', 'voltage-dependent anion'],  # Mitochondrial channel\n",
    "    'CYCS': ['CYCS', 'cytochrome c'],  # Cytochrome c\n",
    "    'BECN1': ['BECN1', 'beclin'],  # Autophagy protein\n",
    "    'CTSD': ['CTSD', 'cathepsin D'],  # Lysosomal protease\n",
    "    'ATG12': ['ATG12', 'autophagy related 12'],  # Autophagy protein\n",
    "    'ULK1': ['ULK1', 'unc-51 like autophagy'],  # Autophagy initiation\n",
    "    'CTSL': ['CTSL', 'cathepsin L'],  # Lysosomal protease\n",
    "    'TAX1BP1': ['TAX1BP1', 'Tax1 binding protein'],  # Autophagy receptor\n",
    "    'CAT': ['CAT', 'catalase'],  # Antioxidant enzyme\n",
    "    'PRDX1': ['PRDX1', 'peroxiredoxin'],  # Antioxidant enzyme\n",
    "    'KEAP1': ['KEAP1', 'kelch like ECH'],  # Oxidative stress regulator\n",
    "    'TFRC': ['TFRC', 'transferrin receptor']  # Iron transport\n",
    "}\n",
    "\n",
    "# Search for each target protein in the dataset\n",
    "found_proteins = {}\n",
    "missing_proteins = []\n",
    "\n",
    "for protein_name, search_terms in target_proteins.items():\n",
    "    # Search in gene names and descriptions\n",
    "    matches = []\n",
    "    \n",
    "    for term in search_terms:\n",
    "        # Case-insensitive search in GeneName column\n",
    "        gene_matches = adata.var[adata.var['GeneName'].str.contains(term, case=False, na=False)]\n",
    "        # Case-insensitive search in Description column\n",
    "        desc_matches = adata.var[adata.var['Description'].str.contains(term, case=False, na=False)]\n",
    "        \n",
    "        matches.extend(gene_matches.index.tolist())\n",
    "        matches.extend(desc_matches.index.tolist())\n",
    "    \n",
    "    # Remove duplicates\n",
    "    matches = list(set(matches))\n",
    "    \n",
    "    if matches:\n",
    "        found_proteins[protein_name] = matches\n",
    "        print(f\"{protein_name}: Found {len(matches)} match(es)\")\n",
    "        for match in matches[:3]:  # Show first 3 matches\n",
    "            gene = adata.var.loc[match, 'GeneName']\n",
    "            desc = adata.var.loc[match, 'Description'][:50] + '...' if len(adata.var.loc[match, 'Description']) > 50 else adata.var.loc[match, 'Description']\n",
    "            print(f\"  - {match}: {gene} | {desc}\")\n",
    "        if len(matches) > 3:\n",
    "            print(f\"  ... and {len(matches)-3} more\")\n",
    "    else:\n",
    "        missing_proteins.append(protein_name)\n",
    "        print(f\"{protein_name}: NOT FOUND\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"Proteins found: {len(found_proteins)}/{len(target_proteins)}\")\n",
    "print(f\"Missing proteins: {missing_proteins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "claim1-header"
   },
   "source": [
    "# Claim 1: Targeted analyses show no significant UPS protein alterations across tau-positive versus tau-negative neurons.\n",
    "\n",
    "## Biological Context\n",
    "\n",
    "The Ubiquitin-Proteasome System (UPS) is the primary pathway for degrading misfolded and damaged proteins in cells. In neurodegenerative diseases, UPS function is often impaired, leading to protein accumulation. However, this claim suggests that UPS proteins themselves are not significantly altered between tau-positive and tau-negative neurons.\n",
    "\n",
    "### UPS Components to Analyze:\n",
    "- **Proteasome subunits**: PSMA1-7, PSMB1-7, PSMD1-14\n",
    "- **E1 enzymes**: UBA1, UBA6\n",
    "- **E2 enzymes**: UBE2 family proteins\n",
    "- **E3 ligases**: Various RING, HECT, and RBR domain proteins\n",
    "- **Deubiquitinases**: USP family proteins\n",
    "\n",
    "## Analytical Approach\n",
    "\n",
    "1. **Identify UPS proteins** in the dataset using systematic annotation\n",
    "2. **Perform differential expression analysis** comparing tau+ vs tau- neurons\n",
    "3. **Apply multiple testing correction** to control false discovery rate\n",
    "4. **Assess effect sizes** to determine biological significance\n",
    "5. **Validate results** with appropriate statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "claim1-analysis-header"
   },
   "source": [
    "## Analysis code\n",
    "\n",
    "Run your analysis code in this section. Important: include detailed markdown explaining your analytical steps and rationale for choosing certain modelling and data processing approaches and similar decisions. We also ask that you comment your code itself thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "claim1-identify-ups-proteins"
   },
   "outputs": [],
   "source": [
    "# Identify UPS (Ubiquitin-Proteasome System) proteins in the dataset\n",
    "print(\"=== IDENTIFYING UPS PROTEINS ===\")\n",
    "\n",
    "# Define comprehensive UPS protein categories and search terms\n",
    "ups_categories = {\n",
    "    'proteasome_20s': ['PSMA', 'PSMB'],  # 20S proteasome subunits\n",
    "    'proteasome_19s': ['PSMD', 'PSMC'],  # 19S regulatory particle\n",
    "    'e1_enzymes': ['UBA1', 'UBA6'],  # Ubiquitin-activating enzymes\n",
    "    'e2_enzymes': ['UBE2', 'UBC'],  # Ubiquitin-conjugating enzymes\n",
    "    'e3_ligases': ['UBR', 'RING', 'HECT', 'RBR', 'TRIM', 'MDM2', 'HUWE1'],  # E3 ligases\n",
    "    'deubiquitinases': ['USP', 'UCH', 'OTU', 'JAMM'],  # Deubiquitinases\n",
    "    'ubiquitin': ['UBB', 'UBC', 'UBA52', 'RPS27A'],  # Ubiquitin proteins\n",
    "    'proteasome_assembly': ['POMP', 'PAC', 'PSMF1', 'PSMG'],  # Assembly factors\n",
    "    'proteasome_activators': ['PSME', 'PA28', 'PA200'],  # Proteasome activators\n",
    "}\n",
    "\n",
    "# Additional UPS-related terms for broader search\n",
    "ups_general_terms = [\n",
    "    'proteasome', 'ubiquitin', 'protease', 'degradation',\n",
    "    'deubiquitinating', 'ubiquitin ligase', 'proteasome subunit'\n",
    "]\n",
    "\n",
    "# Search for UPS proteins in the dataset\n",
    "ups_proteins_found = {}\n",
    "all_ups_indices = set()\n",
    "\n",
    "print(\"Searching for UPS proteins by category...\")\n",
    "\n",
    "for category, terms in ups_categories.items():\n",
    "    category_matches = set()\n",
    "    \n",
    "    for term in terms:\n",
    "        # Search in gene names (primary search)\n",
    "        gene_matches = adata.var[adata.var['GeneName'].str.contains(term, case=False, na=False)].index\n",
    "        category_matches.update(gene_matches)\n",
    "        \n",
    "        # Search in descriptions (secondary search)\n",
    "        desc_matches = adata.var[adata.var['Description'].str.contains(term, case=False, na=False)].index\n",
    "        category_matches.update(desc_matches)\n",
    "    \n",
    "    if category_matches:\n",
    "        ups_proteins_found[category] = list(category_matches)\n",
    "        all_ups_indices.update(category_matches)\n",
    "        print(f\"  {category}: {len(category_matches)} proteins\")\n",
    "    else:\n",
    "        ups_proteins_found[category] = []\n",
    "        print(f\"  {category}: 0 proteins\")\n",
    "\n",
    "# Additional search using general terms\n",
    "print(\"\\nSearching using general UPS terms...\")\n",
    "general_matches = set()\n",
    "\n",
    "for term in ups_general_terms:\n",
    "    # Search in descriptions for general terms\n",
    "    matches = adata.var[adata.var['Description'].str.contains(term, case=False, na=False)].index\n",
    "    general_matches.update(matches)\n",
    "\n",
    "# Remove proteins already found in specific categories\n",
    "additional_ups = general_matches - all_ups_indices\n",
    "all_ups_indices.update(additional_ups)\n",
    "\n",
    "if additional_ups:\n",
    "    ups_proteins_found['general_ups'] = list(additional_ups)\n",
    "    print(f\"  Additional UPS proteins: {len(additional_ups)}\")\n",
    "\n",
    "print(f\"\\n=== UPS PROTEIN IDENTIFICATION SUMMARY ===\")\n",
    "print(f\"Total UPS proteins identified: {len(all_ups_indices)}\")\n",
    "print(f\"Categories with proteins: {sum(1 for cat in ups_proteins_found.values() if cat)}\")\n",
    "\n",
    "# Convert to list for easier handling\n",
    "ups_protein_indices = list(all_ups_indices)\n",
    "\n",
    "# Display sample of identified UPS proteins\n",
    "if ups_protein_indices:\n",
    "    print(f\"\\nSample of identified UPS proteins:\")\n",
    "    sample_indices = ups_protein_indices[:10]  # Show first 10\n",
    "    for idx in sample_indices:\n",
    "        gene = adata.var.loc[idx, 'GeneName']\n",
    "        desc = adata.var.loc[idx, 'Description'][:60] + '...' if len(adata.var.loc[idx, 'Description']) > 60 else adata.var.loc[idx, 'Description']\n",
    "        print(f\"  {idx}: {gene} | {desc}\")\n",
    "    \n",
    "    if len(ups_protein_indices) > 10:\n",
    "        print(f\"  ... and {len(ups_protein_indices)-10} more UPS proteins\")\n",
    "else:\n",
    "    print(\"WARNING: No UPS proteins identified in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "claim1-differential-expression"
   },
   "outputs": [],
   "source": [
    "# Perform differential expression analysis for UPS proteins\n",
    "print(\"=== UPS DIFFERENTIAL EXPRESSION ANALYSIS ===\")\n",
    "\n",
    "if len(ups_protein_indices) == 0:\n",
    "    print(\"ERROR: No UPS proteins found for analysis\")\n",
    "else:\n",
    "    # Extract UPS protein expression data\n",
    "    ups_expr_df = adata.to_df().iloc[:, ups_protein_indices]\n",
    "    \n",
    "    # Get tau status for grouping\n",
    "    tau_status = adata.obs['TauStatus']\n",
    "    \n",
    "    print(f\"Analyzing {len(ups_protein_indices)} UPS proteins\")\n",
    "    print(f\"Sample sizes: Tau+ = {(tau_status == 'positive').sum()}, Tau- = {(tau_status == 'negative').sum()}\")\n",
    "    \n",
    "    # Perform statistical tests for each UPS protein\n",
    "    ups_de_results = []\n",
    "    \n",
    "    for i, protein_idx in enumerate(ups_protein_indices):\n",
    "        # Get expression values for current protein\n",
    "        protein_expr = ups_expr_df.iloc[:, i]\n",
    "        \n",
    "        # Split by tau status\n",
    "        tau_pos_expr = protein_expr[tau_status == 'positive']\n",
    "        tau_neg_expr = protein_expr[tau_status == 'negative']\n",
    "        \n",
    "        # Perform Welch's t-test (unequal variances)\n",
    "        # This is more robust than standard t-test when sample sizes differ\n",
    "        t_stat, p_value = stats.ttest_ind(tau_pos_expr, tau_neg_expr, equal_var=False)\n",
    "        \n",
    "        # Calculate effect size (Cohen's d)\n",
    "        pooled_std = np.sqrt(((len(tau_pos_expr)-1)*tau_pos_expr.var() + \n",
    "                             (len(tau_neg_expr)-1)*tau_neg_expr.var()) / \n",
    "                            (len(tau_pos_expr) + len(tau_neg_expr) - 2))\n",
    "        \n",
    "        if pooled_std > 0:  # Avoid division by zero\n",
    "            cohens_d = (tau_pos_expr.mean() - tau_neg_expr.mean()) / pooled_std\n",
    "        else:\n",
    "            cohens_d = 0\n",
    "        \n",
    "        # Calculate log2 fold change\n",
    "        log2_fc = tau_pos_expr.mean() - tau_neg_expr.mean()\n",
    "        \n",
    "        # Get protein information\n",
    "        gene_name = adata.var.loc[protein_idx, 'GeneName']\n",
    "        \n",
    "        # Store results\n",
    "        ups_de_results.append({\n",
    "            'protein_index': protein_idx,\n",
    "            'gene_name': gene_name,\n",
    "            'log2_fold_change': log2_fc,\n",
    "            'p_value': p_value,\n",
    "            't_statistic': t_stat,\n",
    "            'cohens_d': cohens_d,\n",
    "            'tau_pos_mean': tau_pos_expr.mean(),\n",
    "            'tau_neg_mean': tau_neg_expr.mean(),\n",
    "            'tau_pos_std': tau_pos_expr.std(),\n",
    "            'tau_neg_std': tau_neg_expr.std()\n",
    "        })\n",
    "    \n",
    "    # Convert results to DataFrame for easier manipulation\n",
    "    ups_results_df = pd.DataFrame(ups_de_results)\n",
    "    \n",
    "    print(f\"\\nCompleted differential expression analysis for {len(ups_results_df)} UPS proteins\")\n",
    "    print(f\"Raw p-value range: {ups_results_df['p_value'].min():.2e} to {ups_results_df['p_value'].max():.2e}\")\n",
    "    print(f\"Log2 fold change range: {ups_results_df['log2_fold_change'].min():.3f} to {ups_results_df['log2_fold_change'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "claim1-multiple-testing"
   },
   "outputs": [],
   "source": [
    "# Apply multiple testing correction to UPS protein analysis\n",
    "print(\"=== MULTIPLE TESTING CORRECTION ===\")\n",
    "\n",
    "if 'ups_results_df' in locals() and len(ups_results_df) > 0:\n",
    "    # Apply Benjamini-Hochberg FDR correction\n",
    "    # This controls the expected proportion of false discoveries\n",
    "    rejected, corrected_pvals, alpha_sidak, alpha_bonf = multipletests(\n",
    "        ups_results_df['p_value'], \n",
    "        alpha=0.05, \n",
    "        method='fdr_bh'\n",
    "    )\n",
    "    \n",
    "    # Add corrected results to DataFrame\n",
    "    ups_results_df['fdr_corrected_pvalue'] = corrected_pvals\n",
    "    ups_results_df['significant_fdr'] = rejected\n",
    "    \n",
    "    # Also apply Bonferroni correction for comparison\n",
    "    bonf_rejected, bonf_corrected, _, _ = multipletests(\n",
    "        ups_results_df['p_value'], \n",
    "        alpha=0.05, \n",
    "        method='bonferroni'\n",
    "    )\n",
    "    \n",
    "    ups_results_df['bonferroni_corrected_pvalue'] = bonf_corrected\n",
    "    ups_results_df['significant_bonferroni'] = bonf_rejected\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    ups_results_df['abs_log2_fc'] = np.abs(ups_results_df['log2_fold_change'])\n",
    "    ups_results_df['abs_cohens_d'] = np.abs(ups_results_df['cohens_d'])\n",
    "    \n",
    "    print(f\"Multiple testing correction results:\")\n",
    "    print(f\"  Total UPS proteins tested: {len(ups_results_df)}\")\n",
    "    print(f\"  Significant (raw p < 0.05): {(ups_results_df['p_value'] < 0.05).sum()}\")\n",
    "    print(f\"  Significant (FDR < 0.05): {rejected.sum()}\")\n",
    "    print(f\"  Significant (Bonferroni < 0.05): {bonf_rejected.sum()}\")\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total_ups = len(ups_results_df)\n",
    "    raw_sig_pct = (ups_results_df['p_value'] < 0.05).sum() / total_ups * 100\n",
    "    fdr_sig_pct = rejected.sum() / total_ups * 100\n",
    "    bonf_sig_pct = bonf_rejected.sum() / total_ups * 100\n",
    "    \n",
    "    print(f\"\\nPercentages:\")\n",
    "    print(f\"  Raw significance: {raw_sig_pct:.1f}%\")\n",
    "    print(f\"  FDR significance: {fdr_sig_pct:.1f}%\")\n",
    "    print(f\"  Bonferroni significance: {bonf_sig_pct:.1f}%\")\n",
    "    \n",
    "    # Analyze effect sizes\n",
    "    print(f\"\\nEffect size analysis:\")\n",
    "    print(f\"  Mean |log2FC|: {ups_results_df['abs_log2_fc'].mean():.3f}\")\n",
    "    print(f\"  Mean |Cohen's d|: {ups_results_df['abs_cohens_d'].mean():.3f}\")\n",
    "    print(f\"  Large effects (|log2FC| > 1.0): {(ups_results_df['abs_log2_fc'] > 1.0).sum()}\")\n",
    "    print(f\"  Large effects (|Cohen's d| > 0.8): {(ups_results_df['abs_cohens_d'] > 0.8).sum()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR: No UPS differential expression results available for correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "claim1-detailed-results"
   },
   "outputs": [],
   "source": [
    "# Detailed analysis of UPS protein results\n",
    "print(\"=== DETAILED UPS PROTEIN RESULTS ===\")\n",
    "\n",
    "if 'ups_results_df' in locals() and len(ups_results_df) > 0:\n",
    "    # Sort by FDR-corrected p-value\n",
    "    ups_sorted = ups_results_df.sort_values('fdr_corrected_pvalue')\n",
    "    \n",
    "    print(f\"Top 10 UPS proteins by statistical significance (FDR-corrected):\")\n",
    "    print(\"Rank | Gene | Log2FC | Raw p-val | FDR p-val | Cohen's d | Significant\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, (idx, row) in enumerate(ups_sorted.head(10).iterrows()):\n",
    "        rank = i + 1\n",
    "        gene = row['gene_name'][:10]  # Truncate long names\n",
    "        log2fc = row['log2_fold_change']\n",
    "        raw_p = row['p_value']\n",
    "        fdr_p = row['fdr_corrected_pvalue']\n",
    "        cohens_d = row['cohens_d']\n",
    "        sig_marker = \"***\" if row['significant_fdr'] else \"\"\n",
    "        \n",
    "        print(f\"{rank:2d}   | {gene:10s} | {log2fc:6.3f} | {raw_p:8.2e} | {fdr_p:8.2e} | {cohens_d:7.3f} | {sig_marker}\")\n",
    "    \n",
    "    # Show any significant proteins\n",
    "    significant_ups = ups_results_df[ups_results_df['significant_fdr']]\n",
    "    \n",
    "    if len(significant_ups) > 0:\n",
    "        print(f\"\\n=== SIGNIFICANT UPS PROTEINS (FDR < 0.05) ===\")\n",
    "        print(f\"Found {len(significant_ups)} significant UPS proteins:\")\n",
    "        \n",
    "        for idx, row in significant_ups.iterrows():\n",
    "            gene = row['gene_name']\n",
    "            log2fc = row['log2_fold_change']\n",
    "            fdr_p = row['fdr_corrected_pvalue']\n",
    "            cohens_d = row['cohens_d']\n",
    "            direction = \"UP\" if log2fc > 0 else \"DOWN\"\n",
    "            \n",
    "            print(f\"  {gene}: {direction} {abs(log2fc):.3f} log2FC, FDR p-val = {fdr_p:.2e}, Cohen's d = {cohens_d:.3f}\")\n",
    "            \n",
    "            # Add protein description\n",
    "            protein_desc = adata.var.loc[row['protein_index'], 'Description']\n",
    "            print(f\"    Description: {protein_desc[:100]}...\")\n",
    "    else:\n",
    "        print(f\"\\n=== NO SIGNIFICANT UPS PROTEINS FOUND ===\")\n",
    "        print(f\"Zero UPS proteins show significant alterations (FDR < 0.05)\")\n",
    "        print(f\"This supports the claim that UPS proteins are not significantly altered.\")\n",
    "    \n",
    "    # Summary statistics for claim validation\n",
    "    print(f\"\\n=== CLAIM VALIDATION STATISTICS ===\")\n",
    "    print(f\"Total UPS proteins analyzed: {len(ups_results_df)}\")\n",
    "    print(f\"Significant alterations (FDR < 0.05): {(ups_results_df['significant_fdr']).sum()}\")\n",
    "    print(f\"Percentage significant: {(ups_results_df['significant_fdr']).sum() / len(ups_results_df) * 100:.1f}%\")\n",
    "    \n",
    "    # Effect size summary\n",
    "    mean_abs_fc = ups_results_df['abs_log2_fc'].mean()\n",
    "    mean_abs_d = ups_results_df['abs_cohens_d'].mean()\n",
    "    \n",
    "    print(f\"\\nEffect size summary:\")\n",
    "    print(f\"  Mean absolute log2 fold change: {mean_abs_fc:.3f}\")\n",
    "    print(f\"  Mean absolute Cohen's d: {mean_abs_d:.3f}\")\n",
    "    \n",
    "    # Biological interpretation of effect sizes\n",
    "    if mean_abs_d < 0.2:\n",
    "        effect_interpretation = \"negligible\"\n",
    "    elif mean_abs_d < 0.5:\n",
    "        effect_interpretation = \"small\"\n",
    "    elif mean_abs_d < 0.8:\n",
    "        effect_interpretation = \"medium\"\n",
    "    else:\n",
    "        effect_interpretation = \"large\"\n",
    "    \n",
    "    print(f\"  Overall effect size interpretation: {effect_interpretation}\")\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR: No UPS results available for detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "claim1-results-header"
   },
   "source": [
    "## Results code\n",
    "\n",
    "Put results in this section. This includes generating any final plots or calculating any final values, as well as verbose markdown explaining any conclusions based on the interpretation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "claim1-visualization"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive visualization for UPS protein analysis\n",
    "print(\"=== GENERATING UPS ANALYSIS VISUALIZATION ===\")\n",
    "\n",
    "if 'ups_results_df' in locals() and len(ups_results_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Plot 1: Volcano plot of UPS proteins\n",
    "    x = ups_results_df['log2_fold_change']\n",
    "    y = -np.log10(ups_results_df['fdr_corrected_pvalue'])\n",
    "    \n",
    "    # Color points by significance\n",
    "    colors = ['red' if sig else 'gray' for sig in ups_results_df['significant_fdr']]\n",
    "    \n",
    "    axes[0,0].scatter(x, y, c=colors, alpha=0.7, s=50)\n",
    "    axes[0,0].axhline(y=-np.log10(0.05), color='black', linestyle='--', alpha=0.7, label='FDR = 0.05')\n",
    "    axes[0,0].axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[0,0].set_xlabel('Log2 Fold Change (Tau+ vs Tau-)')\n",
    "    axes[0,0].set_ylabel('-Log10(FDR-corrected p-value)')\n",
    "    axes[0,0].set_title(f'UPS Proteins Volcano Plot\\n({len(ups_results_df)} proteins analyzed)')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text annotation\n",
    "    sig_count = (ups_results_df['significant_fdr']).sum()\n",
    "    axes[0,0].text(0.02, 0.98, f'Significant: {sig_count}/{len(ups_results_df)}', \n",
    "                  transform=axes[0,0].transAxes, verticalalignment='top',\n",
    "                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Plot 2: Distribution of p-values\n",
    "    axes[0,1].hist(ups_results_df['p_value'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,1].axvline(x=0.05, color='red', linestyle='--', label='p = 0.05')\n",
    "    axes[0,1].set_xlabel('Raw p-value')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].set_title('Distribution of Raw p-values')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Distribution of fold changes\n",
    "    axes[1,0].hist(ups_results_df['log2_fold_change'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[1,0].axvline(x=0, color='red', linestyle='--', label='No change')\n",
    "    axes[1,0].set_xlabel('Log2 Fold Change')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].set_title('Distribution of Log2 Fold Changes')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Effect sizes (Cohen's d)\n",
    "    axes[1,1].hist(ups_results_df['cohens_d'], bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1,1].axvline(x=0, color='red', linestyle='--', label='No effect')\n",
    "    # Add effect size interpretation lines\n",
    "    axes[1,1].axvline(x=0.2, color='blue', linestyle=':', alpha=0.5, label='Small effect')\n",
    "    axes[1,1].axvline(x=-0.2, color='blue', linestyle=':', alpha=0.5)\n",
    "    axes[1,1].axvline(x=0.8, color='purple', linestyle=':', alpha=0.5, label='Large effect')\n",
    "    axes[1,1].axvline(x=-0.8, color='purple', linestyle=':', alpha=0.5)\n",
    "    axes[1,1].set_xlabel(\"Cohen's d\")\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    axes[1,1].set_title('Distribution of Effect Sizes')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('UPS Protein Differential Expression Analysis', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"UPS protein analysis visualization completed\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot generate visualization - no UPS results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "claim1-final-assessment"
   },
   "outputs": [],
   "source": [
    "# Final assessment of Claim 1\n",
    "print(\"=== CLAIM 1 COMPREHENSIVE ASSESSMENT ===\")\n",
    "print(\"\\nClaim: 'Targeted analyses show no significant UPS protein alterations\")\n",
    "print(\"across tau-positive versus tau-negative neurons.'\")\n",
    "\n",
    "if 'ups_results_df' in locals() and len(ups_results_df) > 0:\n",
    "    # Key statistics for claim validation\n",
    "    total_ups_proteins = len(ups_results_df)\n",
    "    significant_proteins = (ups_results_df['significant_fdr']).sum()\n",
    "    percentage_significant = significant_proteins / total_ups_proteins * 100\n",
    "    \n",
    "    print(f\"\\n=== QUANTITATIVE RESULTS ===\")\n",
    "    print(f\"Total UPS proteins analyzed: {total_ups_proteins}\")\n",
    "    print(f\"Significant alterations (FDR < 0.05): {significant_proteins}\")\n",
    "    print(f\"Percentage significant: {percentage_significant:.1f}%\")\n",
    "    print(f\"Percentage non-significant: {100 - percentage_significant:.1f}%\")\n",
    "    \n",
    "    # Statistical power assessment\n",
    "    mean_abs_effect = ups_results_df['abs_cohens_d'].mean()\n",
    "    median_pvalue = ups_results_df['p_value'].median()\n",
    "    \n",
    "    print(f\"\\n=== EFFECT SIZE ASSESSMENT ===\")\n",
    "    print(f\"Mean absolute effect size (Cohen's d): {mean_abs_effect:.3f}\")\n",
    "    print(f\"Median raw p-value: {median_pvalue:.3f}\")\n",
    "    \n",
    "    # Categorize effect sizes\n",
    "    negligible_effects = (ups_results_df['abs_cohens_d'] < 0.2).sum()\n",
    "    small_effects = ((ups_results_df['abs_cohens_d'] >= 0.2) & (ups_results_df['abs_cohens_d'] < 0.5)).sum()\n",
    "    medium_effects = ((ups_results_df['abs_cohens_d'] >= 0.5) & (ups_results_df['abs_cohens_d'] < 0.8)).sum()\n",
    "    large_effects = (ups_results_df['abs_cohens_d'] >= 0.8).sum()\n",
    "    \n",
    "    print(f\"\\nEffect size distribution:\")\n",
    "    print(f\"  Negligible (|d| < 0.2): {negligible_effects} ({negligible_effects/total_ups_proteins*100:.1f}%)\")\n",
    "    print(f\"  Small (0.2 ≤ |d| < 0.5): {small_effects} ({small_effects/total_ups_proteins*100:.1f}%)\")\n",
    "    print(f\"  Medium (0.5 ≤ |d| < 0.8): {medium_effects} ({medium_effects/total_ups_proteins*100:.1f}%)\")\n",
    "    print(f\"  Large (|d| ≥ 0.8): {large_effects} ({large_effects/total_ups_proteins*100:.1f}%)\")\n",
    "    \n",
    "    # Direction of changes analysis\n",
    "    upregulated = (ups_results_df['log2_fold_change'] > 0).sum()\n",
    "    downregulated = (ups_results_df['log2_fold_change'] < 0).sum()\n",
    "    unchanged = (ups_results_df['log2_fold_change'] == 0).sum()\n",
    "    \n",
    "    print(f\"\\n=== DIRECTION OF CHANGES ===\")\n",
    "    print(f\"Upregulated (log2FC > 0): {upregulated} ({upregulated/total_ups_proteins*100:.1f}%)\")\n",
    "    print(f\"Downregulated (log2FC < 0): {downregulated} ({downregulated/total_ups_proteins*100:.1f}%)\")\n",
    "    print(f\"Unchanged (log2FC = 0): {unchanged} ({unchanged/total_ups_proteins*100:.1f}%)\")\n",
    "    \n",
    "    # Biological interpretation\n",
    "    print(f\"\\n=== BIOLOGICAL INTERPRETATION ===\")\n",
    "    \n",
    "    if significant_proteins == 0:\n",
    "        biological_conclusion = \"STRONG SUPPORT\"\n",
    "        interpretation = \"No UPS proteins show significant alterations, strongly supporting the claim.\"\n",
    "    elif percentage_significant < 5:\n",
    "        biological_conclusion = \"SUPPORT\"\n",
    "        interpretation = f\"Very few UPS proteins ({percentage_significant:.1f}%) show significant alterations, generally supporting the claim.\"\n",
    "    elif percentage_significant < 10:\n",
    "        biological_conclusion = \"WEAK SUPPORT\"\n",
    "        interpretation = f\"A small proportion ({percentage_significant:.1f}%) of UPS proteins show alterations, providing weak support for the claim.\"\n",
    "    else:\n",
    "        biological_conclusion = \"NO SUPPORT\"\n",
    "        interpretation = f\"A substantial proportion ({percentage_significant:.1f}%) of UPS proteins show significant alterations, contradicting the claim.\"\n",
    "    \n",
    "    print(f\"Biological conclusion: {biological_conclusion}\")\n",
    "    print(f\"Interpretation: {interpretation}\")\n",
    "    \n",
    "    # Technical considerations\n",
    "    print(f\"\\n=== TECHNICAL CONSIDERATIONS ===\")\n",
    "    print(f\"Statistical method: Welch's t-test with FDR correction\")\n",
    "    print(f\"Sample size: Tau+ = {(adata.obs['TauStatus'] == 'positive').sum()}, Tau- = {(adata.obs['TauStatus'] == 'negative').sum()}\")\n",
    "    print(f\"Multiple testing: Benjamini-Hochberg FDR control\")\n",
    "    print(f\"Effect size metric: Cohen's d\")\n",
    "    \n",
    "    # List any significant proteins for transparency\n",
    "    if significant_proteins > 0:\n",
    "        print(f\"\\n=== SIGNIFICANT UPS PROTEINS IDENTIFIED ===\")\n",
    "        significant_ups = ups_results_df[ups_results_df['significant_fdr']]\n",
    "        for idx, row in significant_ups.iterrows():\n",
    "            gene = row['gene_name']\n",
    "            log2fc = row['log2_fold_change']\n",
    "            fdr_p = row['fdr_corrected_pvalue']\n",
    "            direction = \"upregulated\" if log2fc > 0 else \"downregulated\"\n",
    "            print(f\"  {gene}: {direction} (log2FC = {log2fc:.3f}, FDR p-val = {fdr_p:.2e})\")\n",
    "    \n",
    "    # Final validation conclusion\n",
    "    print(f\"\\n=== FINAL CLAIM VALIDATION ===\")\n",
    "    print(f\"Status: {biological_conclusion}\")\n",
    "    print(f\"\\nEvidence summary:\")\n",
    "    print(f\"• {total_ups_proteins} UPS proteins analyzed using rigorous statistical methods\")\n",
    "    print(f\"• {significant_proteins} proteins ({percentage_significant:.1f}%) show significant alterations\")\n",
    "    print(f\"• Mean effect size is {mean_abs_effect:.3f} (Cohen's d), indicating {effect_interpretation} effects\")\n",
    "    print(f\"• Results are consistent with maintained UPS function in tau pathology\")\n",
    "    \n",
    "    if percentage_significant < 5:\n",
    "        print(f\"\\nConclusion: The claim is SUPPORTED by the data. UPS proteins show\")\n",
    "        print(f\"minimal significant alterations between tau-positive and tau-negative neurons.\")\n",
    "    else:\n",
    "        print(f\"\\nConclusion: The claim requires QUALIFICATION. While most UPS proteins\")\n",
    "        print(f\"are unchanged, {significant_proteins} proteins do show significant alterations.\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n=== ANALYSIS LIMITATION ===\")\n",
    "    print(\"Could not complete UPS protein analysis due to protein identification issues.\")\n",
    "    print(\"This may indicate that UPS proteins are either:\")\n",
    "    print(\"1. Not present in the dataset (technical limitation)\")\n",
    "    print(\"2. Named differently than expected (annotation issue)\")\n",
    "    print(\"3. Below detection threshold (biological reality)\")\n",
    "    print(\"\\nRecommendation: Verify protein annotation methods and detection sensitivity.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}